# Anthropic API Key
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (optional, for OpenAI model support)
OPENAI_API_KEY=your_openai_api_key_here

# ============================================================================
# TEXT-TO-SPEECH CONFIGURATION
# ============================================================================
# Choose ONE of the following TTS options:
#   1. ElevenLabs (cloud-based) - Set ELEVENLABS_API_KEY
#   2. XTTS v2 (local) - Set XTTS_ENABLED=true
#   3. StyleTTS 2 (local) - Set STYLETTS2_ENABLED=true
#
# Priority order: StyleTTS 2 > XTTS > ElevenLabs

# ElevenLabs TTS Configuration (optional, cloud-based TTS)
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
# Optional: Custom voice ID (default: Rachel - 21m00Tcm4TlvDq8ikWAM)
# ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
# Optional: Custom model ID (default: eleven_multilingual_v2)
# ELEVENLABS_MODEL_ID=eleven_multilingual_v2
# Optional: Multiple voices (JSON array) - adds voice selector dropdown in settings
# Format: [{"voice_id": "...", "label": "Name", "description": "Optional description"}]
# Example voices:
ELEVENLABS_VOICES='[
    {"voice_id": "21m00Tcm4TlvDq8ikWAM", "label": "Rachel", "description": "Calm female"},
    {"voice_id": "ErXwobaYiN019PkySvjV", "label": "Antoni", "description": "Warm male"}]'

# XTTS v2 Local TTS Configuration (optional, local TTS with voice cloning)
# Requires the XTTS server to be running. Start it with:
#   1. Install PyTorch first (GPU): pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
#      Or for CPU only: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
#   2. Install XTTS deps: pip install -r requirements-xtts.txt
#   3. Run the server: python run_xtts.py
# XTTS_ENABLED=true
# XTTS_API_URL=http://localhost:8020
# XTTS_LANGUAGE=en
# XTTS_VOICES_DIR=./xtts_voices
# Optional: Default speaker sample file path (if not using cloned voices)
# XTTS_DEFAULT_SPEAKER=/path/to/speaker.wav
# Optional: Pre-load speaker latents on startup (comma-separated paths)
# Speaker latents are cached to avoid recomputing them for each TTS request.
# If XTTS_VOICES_DIR/voices.json exists, those voices are also preloaded automatically.
# XTTS_PRELOAD_SPEAKERS=/path/to/speaker1.wav,/path/to/speaker2.wav

# StyleTTS 2 Local TTS Configuration (optional, local TTS with voice cloning)
# StyleTTS 2 takes priority over XTTS and ElevenLabs if enabled.
# Requires the StyleTTS 2 server to be running. Start it with:
#   1. Install PyTorch first (GPU): pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
#      Or for CPU only: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
#   2. Install StyleTTS 2 deps: pip install -r requirements-styletts2.txt
#   3. Run the server: python run_styletts2.py
# STYLETTS2_ENABLED=true
# STYLETTS2_API_URL=http://localhost:8021
# STYLETTS2_VOICES_DIR=./styletts2_voices
# Optional: Default speaker sample file path (if not using cloned voices)
# STYLETTS2_DEFAULT_SPEAKER=/path/to/speaker.wav
# Optional: Pre-load speaker embeddings on startup (comma-separated paths)
# STYLETTS2_PRELOAD_SPEAKERS=/path/to/speaker1.wav,/path/to/speaker2.wav
#
# Phonemizer backend: "gruut" (default, MIT licensed, no system deps) or "espeak"
# gruut is recommended unless you specifically need espeak-ng quality.
# If using espeak, install espeak-ng on your system first.
# STYLETTS2_PHONEMIZER=gruut
#
# Pronunciation fixes: JSON object mapping mispronounced words to phonetic spellings.
# StyleTTS 2 sometimes mispronounces certain words; this fixes them before synthesis.
# Default fixes are used if not set. Set to {} to disable all fixes.
# STYLETTS2_PRONUNCIATION_FIXES='{"turned": "turnd", "learned": "lernd", "burned": "burnd", "earned": "ernd", "into": "in to"}'

# Pinecone Configuration
# Each index represents a different AI entity with separate memory/conversation history
# Format: JSON array of objects with:
#   - index_name: Pinecone index name
#   - label: Display name for the entity
#   - description: Optional description
#   - llm_provider: "anthropic" or "openai" (default: "anthropic")
#   - default_model: Model to use for this entity (optional, uses provider default if not set)
#   - host: url of your Pinecone index's host server
# Example with different providers:
PINECONE_INDEXES='[
    {"index_name": "claude-main", "label": "Claude", "llm_provider": "anthropic", "host": "[Your Pincone index host url]", "default_model": "claude-sonnet-4-5-20250929"},
    {"index_name": "gpt-research", "label": "GPT", "llm_provider": "openai", "host": "[Your Pincone index host url]", "default_model": "GPT-5.1"}
]'

# Database URL (SQLite for development)
HERE_I_AM_DATABASE_URL=sqlite+aiosqlite:///./here_i_am.db

# Optional: PostgreSQL for production
# HERE_I_AM_DATABASE_URL=postgresql+asyncpg://user:password@localhost/here_i_am

# Application Settings
DEBUG=true
