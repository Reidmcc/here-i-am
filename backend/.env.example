# Anthropic API Key
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (optional, for OpenAI model support)
OPENAI_API_KEY=your_openai_api_key_here

# ============================================================================
# TEXT-TO-SPEECH CONFIGURATION
# ============================================================================
# Choose ONE of the following TTS options:
#   1. ElevenLabs (cloud-based) - Set ELEVENLABS_API_KEY
#   2. XTTS v2 (local) - Set XTTS_ENABLED=true
#
# If both are configured, XTTS takes priority over ElevenLabs.

# ElevenLabs TTS Configuration (optional, cloud-based TTS)
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
# Optional: Custom voice ID (default: Rachel - 21m00Tcm4TlvDq8ikWAM)
# ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
# Optional: Custom model ID (default: eleven_multilingual_v2)
# ELEVENLABS_MODEL_ID=eleven_multilingual_v2
# Optional: Multiple voices (JSON array) - adds voice selector dropdown in settings
# Format: [{"voice_id": "...", "label": "Name", "description": "Optional description"}]
# Example voices:
# ELEVENLABS_VOICES='[{"voice_id": "21m00Tcm4TlvDq8ikWAM", "label": "Rachel", "description": "Calm female"}, {"voice_id": "ErXwobaYiN019PkySvjV", "label": "Antoni", "description": "Warm male"}]'

# XTTS v2 Local TTS Configuration (optional, local TTS with voice cloning)
# Requires the XTTS server to be running. Start it with:
#   pip install -r requirements-xtts.txt
#   python run_xtts.py
# XTTS_ENABLED=true
# XTTS_API_URL=http://localhost:8020
# XTTS_LANGUAGE=en
# XTTS_VOICES_DIR=./xtts_voices
# Optional: Default speaker sample file path (if not using cloned voices)
# XTTS_DEFAULT_SPEAKER=/path/to/speaker.wav

# Pinecone Configuration
# Each index represents a different AI entity with separate memory/conversation history
# Format: JSON array of objects with:
#   - index_name: Pinecone index name
#   - label: Display name for the entity
#   - description: Optional description
#   - llm_provider: "anthropic" or "openai" (default: "anthropic")
#   - default_model: Model to use for this entity (optional, uses provider default if not set)
#   - host: url of your Pinecone index's host server
# Example with different providers:
PINECONE_INDEXES='[
    {"index_name": "claude-main", "label": "Claude", "llm_provider": "anthropic", "host": "[Your Pincone index host url]", "default_model": "claude-sonnet-4-5-20250929"},
    {"index_name": "gpt-research", "label": "GPT", "llm_provider": "openai", "host": "[Your Pincone index host url]", "default_model": "GPT-5.1"}
]'

# Database URL (SQLite for development)
HERE_I_AM_DATABASE_URL=sqlite+aiosqlite:///./here_i_am.db

# Optional: PostgreSQL for production
# HERE_I_AM_DATABASE_URL=postgresql+asyncpg://user:password@localhost/here_i_am

# Application Settings
DEBUG=true
